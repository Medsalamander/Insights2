{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b672ac",
   "metadata": {},
   "source": [
    "### Assess\n",
    "\n",
    "- Assessing your data is the second step in data wrangling. When assessing, you're like a detective at work, inspecting your dataset for two things: data quality issues (i.e. content issues) and lack of tidiness (i.e. structural issues).\n",
    "\n",
    "- Quality issues means issues with content eg missing, duplicate or incorrec data\n",
    "\n",
    "- untidy or messy data has specific structural(columns, rows or table) issues which can slow down the process.\n",
    "\n",
    "- Issues can be assessed visually or programmatically.\n",
    "\n",
    "- Dirty data is also known as low quality data\n",
    "\n",
    "#### Assessment steps\n",
    "- Detect issue\n",
    "- Document issue\n",
    "\n",
    "- visual assessment can be directed(Systematically looking through each table of data in a Jupyter notebook or spreadsheet) or non-directed(Scrolling through the data looking for interesting and relevant issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be83ad",
   "metadata": {},
   "source": [
    "### Be sure to seperate detected issues by Quality and Tidiness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c99a0",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "- 'treatments' table: missing HbA1c changes\n",
    "- 'patients' table: zip code is a float not a string\n",
    "- 'patients' table: zip code has four digits sometimes\n",
    "- 'patients' table: Tim Neudorf is 27 inches instead of 72 inches\n",
    "- 'patients' table: full state names sometimes, abbreviations other times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcfa301",
   "metadata": {},
   "source": [
    "### What is the Difference Between Assessing and Exploring?\n",
    "\n",
    "#### Data wrangling is about:\n",
    "\n",
    "- Gathering the right data\n",
    "- Assessing the data's quality and structure\n",
    "- Modifying the data to make it clean\n",
    "\n",
    ">However, your assessments and modification will not make your analysis, visualizations, or models better. It just makes them work.\n",
    "\n",
    "#### Exploratory Data Analysis (EDA) is about:\n",
    "\n",
    "- Exploring the data with simple visualizations that summarize the data's main characteristics\n",
    "- Augmenting the data, for example, removing outliers and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e673c",
   "metadata": {},
   "source": [
    "### Data Quality Dimensions\n",
    "\n",
    ">Data quality dimensions help guide your thought process while assessing and also cleaning. The four main data quality dimensions are:\n",
    "\n",
    "- Completeness: do we have all of the records that we should? Do we have missing records or not? Are there specific rows, columns, or cells missing?\n",
    "- Validity: we have the records, but they're not valid, i.e., they don't conform to a defined schema. A schema is a defined set of rules for data. These rules can be real-world constraints (e.g. negative height is impossible) and table-specific constraints (e.g. unique key constraints in tables).\n",
    "- Accuracy: inaccurate data is wrong data that is valid. It adheres to the defined schema, but it is still incorrect. Example: a patient's weight that is 5 lbs too heavy because the scale was faulty.\n",
    "- Consistency: inconsistent data is both valid and accurate, but there are multiple correct ways of referring to the same thing. Consistency, i.e., a standard format, in columns that represent the same data across tables and/or within tables is desired.\n",
    ">These are listed in decreasing order of severity, meaning that the dimension listed first, completeness, is the most important.\n",
    "\n",
    ">Regarding the other data quality research mentioned in the video, the additional dimensions are specific cases of these four dimensions listed above. Example: currency, defined as follows: the degree to which data is current with the world that it models. Currency can measure how up-to-date data is. Currency is a specific case of accuracy in data in the sense that out-of-date data is (usually) valid but wrong. In other words, our definition of accuracy can include currency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2df56",
   "metadata": {},
   "source": [
    "## Flat file structure\n",
    ">Flat files contain tabular data in plain text format with one data record per line and each record or line having one or more fields. These fields are separated by delimiters, like commas, tabs, or colons.\n",
    "\n",
    ">Advantages of flat files include:\n",
    "\n",
    "- They're text files and therefore human readable\n",
    "- Lightweight\n",
    "- Simple to understand\n",
    "- Software that can read/write text files is ubiquitous, like text editors\n",
    "- Great for small dataset\n",
    "\n",
    ">Disadvantages of flat files, in comparison to relational databases, for example, include:\n",
    "\n",
    "- Lack of standards.\n",
    "- Data redundancy\n",
    "- Sharing data can be cumbersome\n",
    "- Not great for large datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb47620",
   "metadata": {},
   "source": [
    "web scraping, which allows us to extract data from websites using code.\n",
    "\n",
    "How Does Web Scraping Work?\n",
    "Website data is written in HTML (HyperText Markup Language) which uses tags to structure the page. Because HTML and its tags are just text, the text can be accessed using parsers . We'll be using a Python parser called Beautiful Soup. \n",
    "\n",
    "Accessing the HTML\n",
    "Manual Access\n",
    "The quick way to get HTML data is by saving the HTML file to your computer manually. You can do this by clicking Save in your browser.\n",
    "\n",
    "Programmatic Access\n",
    "Programmatic access is preferred for scalability and reproducibility. Two options include:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading HTML file programmatically. We'll explore this code in more detail later\n",
    "import requests\n",
    "url = 'https://www.rottentomatoes.com/m/et_the_extraterrestrial'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save HTML to file\n",
    "\n",
    "with open(\"et_the_extraterrestrial.html\", mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with the response content live in your computer's memory using the BeautifulSoup HTML parser\n",
    "# Work with HTML in memory\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cb7fe",
   "metadata": {},
   "source": [
    "Different Types of HTML Elements\n",
    "\n",
    "Heading elements are used for section headings.\n",
    "<h1>Highest Level Heading Content</h1>\n",
    "<h2>Second Level Heading Content</h2>\n",
    "<h3>Third Level eading Content</h3>\n",
    "<h4>Fourth Level Heading Content</h4>\n",
    "\n",
    "Paragraph elements are used for standard blocks of text\n",
    "<p>This is just a block of text.</p>\n",
    "\n",
    "Span elements are used to group text within another block of text, often for styling\n",
    "<p>This block of text has a <span>element</span> inside it.</p>\n",
    "\n",
    "Image elements are used to embed images in a web page\n",
    "<img src=\"image-file.jpg\" alt=\"text that describes the image\" />\n",
    "\n",
    "Elements Can Go Inside Other Elements\n",
    "We can create a tree structure in HTML by putting elements inside other elements. To do this we often use a <div> element as a container. <div elements are used to group chunks of content together.\n",
    "                                                                                                                                               \n",
    "<div>\n",
    "    <h1>This is a heading.</h1>\n",
    "    <p>This is a paragraph.</p>\n",
    "</div>                                                                                                                                            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import beautiful soup\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# make the soup\n",
    "\n",
    "with open(filepath) as file:\n",
    "    soup = BeautifulSoup(file, 'lxml')\n",
    "    \n",
    "# find and extract data using the find() function\n",
    "soup.find('text_string')\n",
    "\n",
    "#for example\n",
    "soup.find('title')\n",
    "\n",
    "#we get the title element of the webpage, and not the title of the movie.\n",
    "<title>E.T. The Extra-Terrestrial (1982) - Rotten Tomatoes</title>\n",
    "\n",
    "#To get the movie title only, we'll need to do some string slicing.\n",
    "#We can use .contents to return a list of the tag's children. \n",
    "#Because there's only one item with the title tag, the list is one item long so we can access it using the index 0:\n",
    "\n",
    "soup.find('title').count[0][:-len(' - Rotten Tomatoes')]\n",
    "\n",
    "# this gives\n",
    "'The Extra-Terrestrial\\xa0(1982)'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b34e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e852498e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movie' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-484b54fc188d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\veikt\\Documents\\Victor_Obi\\2022\\Data_analysis_project\\Udacity\\Data_Wrangling\\rt-html\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmovie_html\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconyents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' - Rotten Tomatoes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'movie' is not defined"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "folder = r\"C:\\Users\\veikt\\Documents\\Victor_Obi\\2022\\Data_analysis_project\\Udacity\\Data_Wrangling\\rt-html\"\n",
    "for movie_html in os.listdir(folder):\n",
    "    with open(os.path.join(folder, movie-html)) as file:\n",
    "        soup = BeautifulSoup(file)\n",
    "        title = soup.find('title').conyents[0][:-len(' - Rotten Tomatoes')]\n",
    "        print(title)\n",
    "        break\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75908770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
